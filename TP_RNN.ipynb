{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP-RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFLVg82l9rqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.datasets as dsets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI5BDQNl95jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "EPOCH =  # Define the training times\n",
        "BATCH_SIZE = 64\n",
        "TIME_STEP = 28\n",
        "INPUT_SIZE = 28\n",
        "LR = 0.01\n",
        "DOWNLOAD_MNIST = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPduHG2x-Z1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST digital data set\n",
        "train_data = dsets.MNIST(\n",
        "    root='./mnist/',\n",
        "    train=True,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=DOWNLOAD_MNIST,\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poKGc6NX-t1t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "4fb355e6-5ef3-4eb9-f84e-5a4e15f1337c"
      },
      "source": [
        "# Print one of the examples\n",
        "print(train_data.__.__)  # print the torch.Size of data(as below)\n",
        "print(train_data.__.__)  # print the torch.Size of labels(as below)\n",
        "plt.imshow(train_data.train_data[1], cmap='gray')\n",
        "plt.title('%i' % train_data.train_labels[1])\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([60000])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biUpVaPXHc8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=__, # MNIST digital data set\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,    \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly06sZ6zHpR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "fbb07035-2a53-40b8-b869-f7bc7cab7726"
      },
      "source": [
        "# Convert test_data to Variable, and take out the first 2000 as test\n",
        "test_data = dsets.MNIST(\n",
        "    root='./mnist/', \n",
        "    train=False,\n",
        "    transform=transforms.ToTensor(),\n",
        ")\n",
        "test_x = Variable(test_data.test_data, volatile=True).type(torch.FloatTensor)[:2000]/255\n",
        "test_y = test_data.test_labels.numpy().squeeze()[:2000]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXK2imkzIIUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.rnn = nn.LSTM(  # If use nn.RNN(), it is almost impossible to learn\n",
        "            input_size=INPUT_SIZE,\n",
        "            hidden_size=64,  # hidden unit\n",
        "            num_layers=1,  # rnn layers number\n",
        "            batch_first=True,  # The batch size of input & output is 1 dimension. For example (batch, time_step, input_size)\n",
        "        )\n",
        "        self.out = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape (batch, time_step, input_size)\n",
        "        # r_out shape (batch, time_step, output_size)\n",
        "        # h_n shape (n_layers, batch, hidden_size)\n",
        "        # h_c shape (n_layers, batch, hidden_size)\n",
        "        r_out, (h_n, h_c) = self.rnn(x, )  # zero initial hidden state\n",
        "        \n",
        "        # choose r_out at the last time step\n",
        "        out = self.out(r_out[:, -1, :])\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_peOUitIR73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "bfa19c5e-d6fb-427e-f64c-12ad38420f03"
      },
      "source": [
        "rnn = RNN()\n",
        "print(rnn)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (rnn): LSTM(28, 64, batch_first=True)\n",
            "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjaXluRDIeGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ou3WDHYImlf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "1ed4687e-2257-4906-db93-71b3c04365dc"
      },
      "source": [
        "# Train and test neural networks\n",
        "for epoch in range(EPOCH):\n",
        "    for step, (x, y) in enumerate(train_loader):        # gives batch data\n",
        "        b_x = Variable(x.view(-1, 28, 28))              # reshape x to (batch, time_step, input_size)\n",
        "        b_y = Variable(y)                               # batch y\n",
        " \n",
        "        output = __                               # rnn output\n",
        "        loss = loss_func(output, b_y)                   # cross entropy loss\n",
        "        optimizer.__                           # clear gradients for this training step\n",
        "        loss.__                                # backpropagation, compute gradients\n",
        "        optimizer.step()                                # apply gradients\n",
        " \n",
        "        if step % 50 == 0:\n",
        "            test_output = rnn(test_x)                   # (samples, time_step, input_size)\n",
        "            pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
        "            accuracy = sum(pred_y == test_y) / float(test_y.size)\n",
        "            print('Epoch: ', __, '| train loss: %.4f' % __, '| test accuracy: %.2f' % accuracy)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 | train loss: 2.3114 | test accuracy: 0.10\n",
            "Epoch:  0 | train loss: 1.3816 | test accuracy: 0.52\n",
            "Epoch:  0 | train loss: 0.8640 | test accuracy: 0.67\n",
            "Epoch:  0 | train loss: 0.8618 | test accuracy: 0.78\n",
            "Epoch:  0 | train loss: 0.6302 | test accuracy: 0.84\n",
            "Epoch:  0 | train loss: 0.3067 | test accuracy: 0.87\n",
            "Epoch:  0 | train loss: 0.4814 | test accuracy: 0.89\n",
            "Epoch:  0 | train loss: 0.3070 | test accuracy: 0.89\n",
            "Epoch:  0 | train loss: 0.3432 | test accuracy: 0.93\n",
            "Epoch:  0 | train loss: 0.4534 | test accuracy: 0.93\n",
            "Epoch:  0 | train loss: 0.0740 | test accuracy: 0.94\n",
            "Epoch:  0 | train loss: 0.1413 | test accuracy: 0.94\n",
            "Epoch:  0 | train loss: 0.1141 | test accuracy: 0.92\n",
            "Epoch:  0 | train loss: 0.3847 | test accuracy: 0.93\n",
            "Epoch:  0 | train loss: 0.1260 | test accuracy: 0.94\n",
            "Epoch:  0 | train loss: 0.2264 | test accuracy: 0.95\n",
            "Epoch:  0 | train loss: 0.0907 | test accuracy: 0.95\n",
            "Epoch:  0 | train loss: 0.2364 | test accuracy: 0.95\n",
            "Epoch:  0 | train loss: 0.0356 | test accuracy: 0.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUA3uC7aI6PL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4a7a96c7-84c3-44c6-8ebe-083cf236b5bf"
      },
      "source": [
        "# Print the first 10 test values\n",
        "test_output = rnn(test_x[:10].view(-1, 28, 28))\n",
        "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
        "print(pred_y, 'prediction number')\n",
        "print(test_y[:10], 'real number')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 9 9 9 9 9 9 9 9 9] prediction number\n",
            "[7 2 1 0 4 1 4 9 5 9] real number\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}